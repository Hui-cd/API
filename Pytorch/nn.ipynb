{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.nn.LayerNorm` 是 PyTorch 中用于应用层归一化的类。层归一化（Layer Normalization）是一种在深度神经网络中常用的技术，主要用于归一化输入的特征。下面是 `torch.nn.LayerNorm` 的详细参数解释：\n",
    "\n",
    "### 参数\n",
    "\n",
    "- **normalized_shape** (`int` 或 `tuple`): 输入张量的形状，从最后一个维度开始，应用归一化。例如，如果输入的特征张量形状为 `[batch_size, num_features, height, width]`，则 `normalized_shape` 可以是 `[num_features, height, width]` 或 `num_features`。\n",
    "- **eps** (`float`, 可选): 用于数值稳定性的一个小常数，防止除以零。默认值是 `1e-05`。\n",
    "- **elementwise_affine** (`bool`, 可选): 是否为每个元素添加可学习的缩放参数和偏移参数。如果设置为 `True`，则每个特征将有对应的缩放和偏移参数。默认为 `True`。\n",
    "- **bias** (`bool`, 可选): 是否添加偏置项（该参数已弃用，推荐使用 `elementwise_affine` 代替）。\n",
    "- **device** (`torch.device`, 可选): 选择运行LayerNorm的设备（例如：`'cuda:0'` 或 `'cpu'`）。如果未指定，则使用当前默认设备。\n",
    "- **dtype** (`torch.dtype`, 可选): 设置参数的数据类型。如果未指定，则使用默认的数据类型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import LayerNorm\n",
    "\n",
    "# 输入张量的形状是 [batch_size, num_features, height, width]\n",
    "input = torch.randn(10, 20, 50, 50)\n",
    "\n",
    "# 创建 LayerNorm 对象\n",
    "layer_norm = LayerNorm([20, 50, 50])\n",
    "\n",
    "# 应用层归一化\n",
    "output = layer_norm(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.triu 函数的基本用法\n",
    "参数:\n",
    "input (Tensor)：输入的二维张量（矩阵）。\n",
    "diagonal (int, 可选)：控制哪一条对角线以上的元素应该被保留。\n",
    "diagonal=0：保留主对角线及其以上的元素。\n",
    "diagonal=1：保留主对角线上方的元素。\n",
    "diagonal=-1：保留主对角线及其下方一条对角线的元素。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Matrix:\n",
      " tensor([[0.9222, 0.7130, 0.2831, 0.4549],\n",
      "        [0.2785, 0.5111, 0.5648, 0.7722],\n",
      "        [0.5796, 0.2247, 0.2990, 0.4520],\n",
      "        [0.7229, 0.3689, 0.9810, 0.5729]])\n",
      "Upper Triangular Matrix:\n",
      " tensor([[0.9222, 0.7130, 0.2831, 0.4549],\n",
      "        [0.0000, 0.5111, 0.5648, 0.7722],\n",
      "        [0.0000, 0.0000, 0.2990, 0.4520],\n",
      "        [0.0000, 0.0000, 0.0000, 0.5729]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.rand(4, 4)  # 创建一个4x4的随机矩阵\n",
    "print(\"Original Matrix:\\n\", a)\n",
    "upper_tri = torch.triu(a)\n",
    "print(\"Upper Triangular Matrix:\\n\", upper_tri)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 PyTorch 中，transpose 方法用于交换张量的两个维度。当你看到如 key.transpose(-2, -1) 的调用时，这里的 -2 和 -1 是指张量的维度索引，其中负数索引表示从后向前数。\n",
    "\n",
    "解释维度索引\n",
    "-1 代表最后一个维度。\n",
    "-2 代表倒数第二个维度。\n",
    "示例与应用\n",
    "假设我们有一个三维张量，形状为 (10, 20, 30)，表示10个20x30的矩阵。调用 transpose(-2, -1) 会交换最后两个维度，结果张量的形状将变为 (10, 30, 20)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor shape: torch.Size([3, 2, 3])\n",
      "Transposed tensor shape: torch.Size([3, 3, 2])\n",
      "\n",
      "Original tensor:\n",
      "tensor([[[ 0.4072,  0.9948, -0.0123],\n",
      "         [ 0.2405,  0.0720, -1.5082]],\n",
      "\n",
      "        [[-1.1210,  1.4243,  0.2197],\n",
      "         [-1.0906, -1.5585, -0.4028]],\n",
      "\n",
      "        [[ 0.9433, -0.0157,  0.1985],\n",
      "         [-1.2856, -0.6498,  0.1067]]])\n",
      "\n",
      "Transposed tensor:\n",
      "tensor([[[ 0.4072,  0.2405],\n",
      "         [ 0.9948,  0.0720],\n",
      "         [-0.0123, -1.5082]],\n",
      "\n",
      "        [[-1.1210, -1.0906],\n",
      "         [ 1.4243, -1.5585],\n",
      "         [ 0.2197, -0.4028]],\n",
      "\n",
      "        [[ 0.9433, -1.2856],\n",
      "         [-0.0157, -0.6498],\n",
      "         [ 0.1985,  0.1067]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a randomly initialized tensor with shape (3, 2, 1)\n",
    "tensor = torch.randn(3, 2, 3)\n",
    "\n",
    "# Transpose the last two dimensions\n",
    "transposed_tensor = tensor.transpose(-2, -1)\n",
    "\n",
    "# Print the shapes of the original and transposed tensors\n",
    "print(\"Original tensor shape:\", tensor.shape)  # Expected output: (3, 2, 1)\n",
    "print(\"Transposed tensor shape:\", transposed_tensor.shape)  # Expected output: (3, 1, 2)\n",
    "\n",
    "# Display the original and transposed tensors\n",
    "print(\"\\nOriginal tensor:\")\n",
    "print(tensor)\n",
    "print(\"\\nTransposed tensor:\")\n",
    "print(transposed_tensor)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
