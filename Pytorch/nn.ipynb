{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.nn.LayerNorm` 是 PyTorch 中用于应用层归一化的类。层归一化（Layer Normalization）是一种在深度神经网络中常用的技术，主要用于归一化输入的特征。下面是 `torch.nn.LayerNorm` 的详细参数解释：\n",
    "\n",
    "### 参数\n",
    "\n",
    "- **normalized_shape** (`int` 或 `tuple`): 输入张量的形状，从最后一个维度开始，应用归一化。例如，如果输入的特征张量形状为 `[batch_size, num_features, height, width]`，则 `normalized_shape` 可以是 `[num_features, height, width]` 或 `num_features`。\n",
    "- **eps** (`float`, 可选): 用于数值稳定性的一个小常数，防止除以零。默认值是 `1e-05`。\n",
    "- **elementwise_affine** (`bool`, 可选): 是否为每个元素添加可学习的缩放参数和偏移参数。如果设置为 `True`，则每个特征将有对应的缩放和偏移参数。默认为 `True`。\n",
    "- **bias** (`bool`, 可选): 是否添加偏置项（该参数已弃用，推荐使用 `elementwise_affine` 代替）。\n",
    "- **device** (`torch.device`, 可选): 选择运行LayerNorm的设备（例如：`'cuda:0'` 或 `'cpu'`）。如果未指定，则使用当前默认设备。\n",
    "- **dtype** (`torch.dtype`, 可选): 设置参数的数据类型。如果未指定，则使用默认的数据类型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import LayerNorm\n",
    "\n",
    "# 输入张量的形状是 [batch_size, num_features, height, width]\n",
    "input = torch.randn(10, 20, 50, 50)\n",
    "\n",
    "# 创建 LayerNorm 对象\n",
    "layer_norm = LayerNorm([20, 50, 50])\n",
    "\n",
    "# 应用层归一化\n",
    "output = layer_norm(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.triu 函数的基本用法\n",
    "参数:\n",
    "input (Tensor)：输入的二维张量（矩阵）。\n",
    "diagonal (int, 可选)：控制哪一条对角线以上的元素应该被保留。\n",
    "diagonal=0：保留主对角线及其以上的元素。\n",
    "diagonal=1：保留主对角线上方的元素。\n",
    "diagonal=-1：保留主对角线及其下方一条对角线的元素。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Matrix:\n",
      " tensor([[0.9222, 0.7130, 0.2831, 0.4549],\n",
      "        [0.2785, 0.5111, 0.5648, 0.7722],\n",
      "        [0.5796, 0.2247, 0.2990, 0.4520],\n",
      "        [0.7229, 0.3689, 0.9810, 0.5729]])\n",
      "Upper Triangular Matrix:\n",
      " tensor([[0.9222, 0.7130, 0.2831, 0.4549],\n",
      "        [0.0000, 0.5111, 0.5648, 0.7722],\n",
      "        [0.0000, 0.0000, 0.2990, 0.4520],\n",
      "        [0.0000, 0.0000, 0.0000, 0.5729]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.rand(4, 4)  # 创建一个4x4的随机矩阵\n",
    "print(\"Original Matrix:\\n\", a)\n",
    "upper_tri = torch.triu(a)\n",
    "print(\"Upper Triangular Matrix:\\n\", upper_tri)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
